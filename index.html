<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Calculator</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --accent-color: #8844ff;
            --listening-color: #ff4466;
            --text-glow-primary: rgba(255, 255, 255, 0.4);
            --text-glow-secondary: rgba(136, 68, 255, 0.5);
        }

        * {
            box-sizing: border-box;
            /* Use the new futuristic font */
            font-family: 'Orbitron', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        }

        html, body {
            height: 100%;
            margin: 0;
            padding: 0;
            overflow: hidden;
        }

        body {
            display: flex;
            flex-direction: column;
            justify-content: flex-end;
            align-items: center;
            /* Set the new black background */
            background: #000000;
            color: rgba(255, 255, 255, 0.8);
            position: relative; /* Needed for the pseudo-element */
        }

        /* Gradient that appears only on the edges when mic is on */
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            background: radial-gradient(ellipse at center, transparent 60%, var(--accent-color) 120%);
            opacity: 0;
            transition: opacity 0.5s ease-in-out;
            z-index: 0; 
        }

        /* Class added via JS to trigger the gradient */
        body.mic-on::before {
            opacity: 0.6;
        }

        #display-container {
            width: 100%;
            flex-grow: 1;
            display: flex;
            flex-direction: column-reverse;
            align-items: center;
            padding: 20px;
            overflow-y: auto;
            scrollbar-width: none; /* Firefox */
            z-index: 1;
        }
        
        #display-container::-webkit-scrollbar {
            display: none; /* Safari and Chrome */
        }
        
        .calculation-entry {
            text-align: center;
            margin-bottom: 2rem;
            transition: all 0.6s cubic-bezier(0.25, 0.8, 0.25, 1);
        }

        /* Apply glassmorphism effect to fonts */
        .expression, .result {
            text-shadow: 0 0 8px var(--text-glow-primary), 0 0 20px var(--text-glow-secondary);
        }
        
        .expression {
            font-size: 1.5rem;
            opacity: 0.7;
            margin: 0;
            min-height: 27px;
            word-wrap: break-word;
            max-width: 90vw;
            color: rgba(255, 255, 255, 0.7);
        }

        .result {
            font-size: 4rem;
            font-weight: bold;
            color: rgba(255, 255, 255, 0.95);
            margin: 0;
            line-height: 1;
            min-height: 64px;
        }
        
        .calculation-entry.history {
            transform: translateY(-20px) scale(0.7);
            opacity: 0.3;
        }

        #voice-button {
            padding: 20px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            margin-bottom: 5vh;
            background-color: var(--accent-color);
            box-shadow: 0 0 25px rgba(136, 68, 255, 0.7);
            transition: all 0.2s ease;
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 10;
        }

        #voice-button:hover {
            transform: scale(1.1);
        }
        
        #voice-button.listening {
            background-color: var(--listening-color);
            box-shadow: 0 0 35px rgba(255, 68, 102, 0.8);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        #voice-button svg {
            width: 32px;
            height: 32px;
            fill: white;
        }
        
        #initial-message {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -100%);
            color: rgba(255, 255, 255, 0.6);
            font-size: 1.2rem;
            text-align: center;
            pointer-events: none;
            transition: opacity 0.5s ease;
            z-index: 1;
        }

        #gemini-badge {
            position: fixed;
            bottom: 20px;
            color: rgba(255, 255, 255, 0.4);
            font-size: 0.8rem;
            pointer-events: none;
            z-index: 1;
        }
    </style>
</head>
<body>
    <div id="initial-message">
        <p>Click the microphone to start/stop.</p>
        <p>Try "three fifty five times two".</p>
    </div>

    <div id="display-container">
        </div>

    <button id="voice-button">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z"/></svg>
    </button>
    <br>
    <p id="gemini-badge">Powered by team vibers</p>

    <script>
        const voiceButton = document.getElementById('voice-button');
        const displayContainer = document.getElementById('display-container');
        const initialMessage = document.getElementById('initial-message');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;
        if (!SpeechRecognition) {
            initialMessage.innerHTML = "<p>Sorry, your browser doesn't support the Web Speech API.</p><p>Please try Chrome or Edge.</p>";
        } else {
            recognition = new SpeechRecognition();
        }

        let userWantsToListen = false;
        let accumulatedTranscript = '';
        let currentDisplay = null;
        
        if (recognition) {
            recognition.continuous = false;
            recognition.lang = 'en-US';
            recognition.interimResults = true;
        
            recognition.onstart = () => {
                voiceButton.classList.add('listening');
                // Add class to body to show gradient
                document.body.classList.add('mic-on');
                initialMessage.style.opacity = '0';
            };
        
            recognition.onend = async () => {
                // Remove class from body to hide gradient
                document.body.classList.remove('mic-on');
                
                if (userWantsToListen) {
                    try {
                        recognition.start();
                    } catch (e) {
                        console.error("Recognition restart failed", e);
                        voiceButton.classList.remove('listening');
                    }
                    return;
                }
                voiceButton.classList.remove('listening');
                if (accumulatedTranscript) {
                    await processCalculation(accumulatedTranscript.trim());
                }
                currentDisplay = null;
            };
        
            recognition.onerror = (event) => {
                // Also remove class on error
                document.body.classList.remove('mic-on');
                if (event.error === 'not-allowed') {
                    userWantsToListen = false;
                    handlePermissionDenied();
                } else if (event.error === 'no-speech' || event.error === 'aborted') {
                    console.log(`Speech recognition event: ${event.error}. This is normal.`);
                } else {
                    console.error("Speech recognition error:", event.error);
                    if (currentDisplay) {
                        currentDisplay.querySelector('.expression').textContent = 'Sorry, I had trouble hearing.';
                        currentDisplay.querySelector('.result').textContent = 'Error';
                    }
                }
            };
        
            recognition.onresult = (event) => {
                let interimTranscript = "";
            
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        accumulatedTranscript += transcript.trim() + " ";
                    } else {
                        interimTranscript += transcript;
                    }
                }
            
                if (!currentDisplay) {
                    document.querySelectorAll('.calculation-entry:not(.history)').forEach(entry => {
                        entry.classList.add('history');
                    });
                    currentDisplay = createDisplayEntry('Listening...');
                    displayContainer.insertAdjacentElement('afterbegin', currentDisplay);
                }
            
                currentDisplay.querySelector('.expression').textContent =
                    accumulatedTranscript + interimTranscript;
            };
        }
        function handlePermissionDenied() {
            initialMessage.innerHTML = "<p>Microphone access is blocked.</p><p>Please enable it in your browser settings to use voice commands.</p>";
            initialMessage.style.opacity = '1';
        }

        voiceButton.addEventListener('click', async () => {
            if (!recognition) return;
            
            try {
                const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
                if (permissionStatus.state === 'denied') {
                    handlePermissionDenied();
                    return;
                }
            } catch(e) {
                console.warn("Permissions API not fully supported, proceeding with normal flow.");
            }

            if (!userWantsToListen) {
                userWantsToListen = true;
                accumulatedTranscript = '';
                try {
                    recognition.start();
                } catch(e) { console.error("Could not start recognition:", e); }
            } else {
                userWantsToListen = false;
                recognition.stop();
            }
        });
        
        function createDisplayEntry(expressionText, resultText = '') {
            const entryDiv = document.createElement('div');
            entryDiv.className = 'calculation-entry';
            
            const expressionP = document.createElement('p');
            expressionP.className = 'expression';
            expressionP.textContent = expressionText;

            const resultH1 = document.createElement('h1');
            resultH1.className = 'result';
            resultH1.textContent = resultText;

            entryDiv.appendChild(expressionP);
            entryDiv.appendChild(resultH1);
            return entryDiv;
        }

        async function processCalculation(text) {
            if (!currentDisplay || !text.trim()) return;
            currentDisplay.querySelector('.expression').textContent = text.trim();
            currentDisplay.querySelector('.result').textContent = '...';
            
            try {
                // NOTE: Replace with your actual Gemini API Key
                const processedText = await textToMathWithGemini(text, "YOUR_API_KEY_HERE"); 
                const result = new Function('return ' + processedText)();

                if (isNaN(result) || !isFinite(result)) {
                    throw new Error("Invalid calculation from API");
                }
                
                const displayExpression = processedText.replace(/\*/g, 'ร').replace(/\//g, 'รท');
                currentDisplay.querySelector('.expression').textContent = displayExpression;
                currentDisplay.querySelector('.result').textContent = parseFloat(result.toFixed(10));

            } catch (error) {
                console.error("Calculation error:", error);
                currentDisplay.querySelector('.expression').textContent = text;
                currentDisplay.querySelector('.result').textContent = 'Error';
            }
        }
        
        async function textToMathWithGemini(text, apiKey) {
            // WARNING: The key in your original code is visible. 
            // It's best practice to replace it here or manage it securely.
            if (apiKey === "YOUR_API_KEY_HERE" && "AIzaSyBQgzwyQLM_3DiE-g2mqSQm78vttByW-KQ") {
                apiKey = "AIzaSyBQgzwyQLM_3DiE-g2mqSQm78vttByW-KQ";
            }
            if (apiKey === "YOUR_API_KEY_HERE") {
                 console.error("API Key is not set.");
                 throw new Error("API Key is not set.");
            }

            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${apiKey}`;

            const systemPrompt = `You are a highly advanced calculator. Your sole purpose is to convert natural language text into a raw, runnable mathematical expression.
- Listen to the user's request.
- Extract all numbers and mathematical operators.
- Correctly apply the order of operations (BODMAS/PEMDAS) by using parentheses where necessary. For example, "2 plus 3 times 5" should be "2 + (3 * 5)".
- Respond with ONLY the final mathematical expression. Do not include any other words, explanations, or formatting like markdown.

Example 1:
User: "what is three hundred fifty five times two"
Response: "355 * 2"

Example 2:
User: "100 divided by 5 plus 20"
Response: "(100 / 5) + 20"`;

            const payload = {
                contents: [{ parts: [{ text: text }] }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`API request failed with status ${response.status}`);
                }

                const result = await response.json();
                const candidate = result.candidates?.[0];

                if (candidate && candidate.content?.parts?.[0]?.text) {
                    const mathExpression = candidate.content.parts[0].text.trim();
                    console.log("Gemini Response:", mathExpression);
                    // Final safety check to prevent unwanted code execution
                    if (/^[0-9+\-*/().\s]+$/.test(mathExpression)) {
                         return mathExpression;
                    } else {
                        throw new Error("API returned an invalid or unsafe expression.");
                    }
                } else {
                    throw new Error("Invalid response structure from API.");
                }
            } catch (error)
            {
                console.error("Gemini API Error:", error);
                throw error; // Re-throw to be caught by processCalculation
            }
        }

    </script>
</body>
</html>
